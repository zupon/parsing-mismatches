{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select language\n",
    "language = \"english\"\n",
    "# language = \"persian\"\n",
    "\n",
    "# Select number of sentences for each corpus\n",
    "num_sents = 250\n",
    "\n",
    "# Select number of similar words to create new word pairs\n",
    "top_n = 10\n",
    "# threshold = [0.95, 0.9, 0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2, 0.1, 0,0]\n",
    "threshold = 0.0\n",
    "\n",
    "# Select seed for training data (1-5)\n",
    "seed = 3\n",
    "\n",
    "BorC = \"B\"\n",
    "# BorC = \"C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_A, corpus_B = f.load_corpus(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./glove.840B.300d.magnitude\n",
      "vectors/english_corpus=A_sents=250_seed=3.magnitude\n"
     ]
    }
   ],
   "source": [
    "vectors = f.load_vectors(language)\n",
    "# vector_type = \"fastText\"\n",
    "vector_type = \"GloVe\"\n",
    "bert_vectors = \"vectors/\"+language+\"_corpus=A_sents=\"+str(num_sents)+\"_seed=\"+str(seed)+\".magnitude\"\n",
    "print(vectors)\n",
    "print(bert_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get word-word-relation triples for each corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_A = \"train_data/en/\"+language+\"_train_corpus=A_sents=\"+str(num_sents)+\"_seed=\"+str(seed)+\".txt\"\n",
    "corpus_B = \"train_data/en/\"+language+\"_train_corpus=\"+BorC+\"_sents=\"+str(num_sents)+\"_seed=\"+str(seed)+\".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 sentences processed\n",
      "4,677 tokens processed\n",
      "Average sentence length:\t18.708\n",
      "4,438 head-dependent:relation pairs\n",
      "4,447 head-dependent-relation:sentence triples\n"
     ]
    }
   ],
   "source": [
    "list_A, sentences_A = f.process_training_data(corpus_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 sentences processed\n",
      "6,333 tokens processed\n",
      "Average sentence length:\t25.332\n",
      "5,704 head-dependent:relation pairs\n",
      "5,723 head-dependent-relation:sentence triples\n"
     ]
    }
   ],
   "source": [
    "list_B, sentences_B = f.process_training_data(corpus_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_A = language+\"_A_mismatches\"+\".tsv\"\n",
    "# output_B = language+\"_B_mismatches\"+\".tsv\"\n",
    "# get list for corpus A data\n",
    "# list_A, sentences_A = f.process_ud_data(corpus_A, num_sents_A)\n",
    "# get list for corpus B data\n",
    "# need to keep process_wsj_data for now for English data\n",
    "# list_B, sentences_B = f.process_wsj_data(corpus_B, num_sents_B)\n",
    "# list_B, sentences_B = f.process_ud_data(corpus_B, num_sents_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for triple in sentences_A:\n",
    "#     print(triple, sentences_A[triple])\n",
    "# for sentence in sentences_A[triple]:\n",
    "#     print(triple, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for triple in sentences_B:\n",
    "# #     print(triple, sentences_B[triple])\n",
    "#     for sentence in sentences_B[triple]:\n",
    "#         print(triple, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare triples from each corpus to find mismatched relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches_A = {}\n",
    "mismatches_B = {}\n",
    "for pair_B in list_B.keys():\n",
    "    # If the (head, dependent) pair is in both corpus A and B\n",
    "    if pair_B in list_A.keys():\n",
    "        # get the relations for that pair in B and in A\n",
    "        relations_B = list_B[pair_B]\n",
    "        relations_A = list_A[pair_B]\n",
    "        # TODO: decide which ones we actually care about...\n",
    "        # get the relations in B NOT in A and relations in A NOT in B\n",
    "        not_in_A = [x for x in relations_B if x not in set(relations_A)]\n",
    "        not_in_B = [x for x in relations_A if x not in set(relations_B)]\n",
    "        # if there are relations not in A/B,\n",
    "        # add entry to mismatches_A or mismatches_B for that pair-relation combo\n",
    "        if len(not_in_A) != 0:\n",
    "            mismatches_B[pair_B] = not_in_A\n",
    "        if len(not_in_B) != 0:\n",
    "            mismatches_A[pair_B] = not_in_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 pairs with a relation in corpus A but not in corpus B\n",
      "13 pairs with a relation in corpus B but not in corpus A\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(mismatches_A)} pairs with a relation in corpus A but not in corpus B\")\n",
    "print(f\"{len(mismatches_B)} pairs with a relation in corpus B but not in corpus A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most Frequent Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate conversion dictionaries and spreadsheet for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_A_simple = f.get_conversions_simple(mismatches_A, \n",
    "                                               sentences_A, \n",
    "                                               list_A, \n",
    "                                               list_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_B_simple = f.get_conversions_simple(mismatches_B, \n",
    "                                               sentences_B, \n",
    "                                               list_B, \n",
    "                                               list_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create human-readable spreadsheet for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# human_readable_A_simple = \"human_readable/\"+corpus_A[11:-4]+\"_simple_human_readable.tsv\"\n",
    "# human_readable_B_simple = \"human_readable/\"+corpus_B[11:-4]+\"_simple_human_readable.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.generate_human_readable_output(human_readable_A_simple, mismatches_A, sentences_A, list_A, list_B)\n",
    "# f.generate_human_readable_output(human_readable_B_simple, mismatches_B, sentences_B, list_B, list_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create converted conllu files for corpus A and corpus B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted_corpus_A_simple = corpus_A[:-4]+\"_converted_simple.conllu\"\n",
    "converted_corpus_B_simple = corpus_B[:-4]+\"_converted_simple.conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.apply_conversions(corpus_A, converted_corpus_A_simple, conversion_A_simple)\n",
    "f.apply_conversions(corpus_B, converted_corpus_B_simple, conversion_B_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate conversion dictionaries and spreadsheet for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresh = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for thresh in threshold:\n",
    "#     conversion_A_pretrained = f.get_conversions_pretrained(mismatches_A, \n",
    "#                                                            sentences_A, \n",
    "#                                                            list_A, \n",
    "#                                                            list_B,\n",
    "#                                                            vectors,\n",
    "#                                                            top_n,\n",
    "#                                                            thresh)\n",
    "#     converted_corpus_A_pretrained = corpus_A[:-4]+\"_converted_pretrained=\"+vector_type+\"_thresh=\"+str(thresh)+\".conllu\"\n",
    "#     f.apply_conversions(corpus_A, converted_corpus_A_pretrained, conversion_A_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_B_pretrained = f.get_conversions_pretrained(mismatches_B, \n",
    "                                                       sentences_B, \n",
    "                                                       list_B, \n",
    "                                                       list_A,\n",
    "                                                       vectors,\n",
    "                                                       top_n,\n",
    "                                                       threshold)\n",
    "converted_corpus_B_pretrained = corpus_B[:-4]+\"_converted_pretrained=\"+vector_type+\".conllu\"\n",
    "f.apply_conversions(corpus_B, converted_corpus_B_pretrained, conversion_B_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create converted files for corpus A and corpus B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converted_corpus_A_pretrained = corpus_A[:-4]+\"_converted_pretrained=\"+vector_type+\".conllu\"\n",
    "# converted_corpus_B_pretrained = corpus_B[:-4]+\"_converted_pretrained=\"+vector_type+\".conllu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.apply_conversions(corpus_A, converted_corpus_A_pretrained, conversion_A_pretrained)\n",
    "# f.apply_conversions(corpus_B, converted_corpus_B_pretrained, conversion_B_pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_B_BERT = f.get_conversions_pretrained(mismatches_B, \n",
    "                                                       sentences_B, \n",
    "                                                       list_B, \n",
    "                                                       list_A,\n",
    "                                                       vectors,\n",
    "                                                       top_n,\n",
    "                                                       threshold)\n",
    "converted_corpus_B_BERT = corpus_B[:-4]+\"_converted_BERT.conllu\"\n",
    "f.apply_conversions(corpus_B, converted_corpus_B_BERT, conversion_B_BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
